{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import data_util as du\n",
    "import performance_util as pu\n",
    "import importlib\n",
    "from PCA import PCA\n",
    "import kmeans\n",
    "import softmax_logit as logsoft\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_util' from 'E:\\\\7th_Sem\\\\Machine Learning\\\\Assignments\\\\Assignment_2\\\\src\\\\data_util.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = './data/Notes/new_mnist/'\n",
    "importlib.reload(du)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir2 = './data/mnist/'\n",
    "random_seed = 1\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 1)\n",
      "(7947, 784)\n",
      "(7947, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = load_mnist(data_dir2)\n",
    "Y_train = Y_train.reshape(len(Y_train) , 1)\n",
    "\n",
    "#X_test, Y_test = du.load_fashion_mnist(data_dir + 't10k')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "X_test, Y_test = du.load_mnistx(data_dir,10)\n",
    "Y_test = Y_test.reshape(len(Y_test), 1)\n",
    "\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, Y_train, X_test , Y_test = du.split_data(X_train, Y_train, 0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = du.normalize2(X_train)\n",
    "X_test = du.normalize2(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 1)\n",
      "(7947, 784)\n",
      "(7947, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9078218541788241\n",
      "(60000, 100)\n",
      "(7947, 100)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=100)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_reduced_1 = pca.transform(X_train)\n",
    "X_test_reduced_1 = pca.transform(X_test)\n",
    "\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "\n",
    "print(X_train_reduced_1.shape)\n",
    "print(X_test_reduced_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logist= logsoft.softmaxLogit( iterations = 80000, Lambda= 0.0, alpha = 0.015, num_classes =10)\n",
    "\n",
    "logist.fit(X_train_reduced_1, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4373977601610671\n",
      "macro_average:  [0.4081 0.4335 0.4204]\n",
      "micro_average:  [0.4374 0.4374 0.4374]\n",
      "f1:  [[0.7281]\n",
      " [0.5566]\n",
      " [0.4213]\n",
      " [0.6192]\n",
      " [0.4046]\n",
      " [0.2574]\n",
      " [0.2855]\n",
      " [0.152 ]\n",
      " [0.5082]\n",
      " [0.1674]]\n",
      "precision:  [[0.6148]\n",
      " [0.4686]\n",
      " [0.5069]\n",
      " [0.5621]\n",
      " [0.3904]\n",
      " [0.2997]\n",
      " [0.3732]\n",
      " [0.1584]\n",
      " [0.4685]\n",
      " [0.2384]]\n",
      "recall: [[0.8926]\n",
      " [0.6853]\n",
      " [0.3604]\n",
      " [0.6893]\n",
      " [0.4199]\n",
      " [0.2256]\n",
      " [0.2312]\n",
      " [0.1461]\n",
      " [0.5553]\n",
      " [0.1289]]\n"
     ]
    }
   ],
   "source": [
    "result= logist.predict(X_test_reduced_1)\n",
    "\n",
    "result = result.reshape((len(X_test_reduced_1),))\n",
    "Y_test = Y_test.reshape((len(X_test_reduced_1),))\n",
    "\n",
    "#np.savetxt(\"foo.csv\", a, delimiter=\",\")\n",
    "\n",
    "print( \"Accuracy:\" , pu.model_accuracy(result, Y_test))\n",
    "print( \"macro_average: \", pu.model_macro_average(result, Y_test, 10))\n",
    "print(\"micro_average: \", pu.model_micro_average(result, Y_test, 10))\n",
    "print( \"f1: \", pu.model_f1(result, Y_test,10))\n",
    "print(\"precision: \", pu.model_precision(result, Y_test,10))\n",
    "print(\"recall:\", pu.model_recall(result, Y_test,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7947,)\n"
     ]
    }
   ],
   "source": [
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"foo.csv\", Y_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.10557443060274317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\" \n",
    "clf = SVC(kernel='poly', degree= 4) \n",
    "  \n",
    "# fitting x samples and y classes \n",
    "clf.fit(X_train_reduced_1, Y_train)\n",
    "\n",
    "result = clf.predict(X_test_reduced_1) \n",
    "\n",
    "result = result.reshape((len(X_test_reduced_1),))\n",
    "Y_test = Y_test.reshape((len(X_test_reduced_1),))\n",
    "#np.savetxt(\"foo.csv\", Y_test, delimiter=\",\")\n",
    "\n",
    "print( \"Accuracy:\" , pu.model_accuracy(result, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7947,)\n",
      "Accuracy: 0.10557443060274317\n"
     ]
    }
   ],
   "source": [
    "print(result.shape)\n",
    "print( \"Accuracy:\" , pu.model_accuracy(result, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-4,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [0,784])\n",
    "y = tf.placeholder(tf.float32, [0, 10])\n",
    "\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope( \"Wx_b\") as scope:\n",
    "    model= tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "w_h = tf.summary.histogram(\"weights\", W)\n",
    "b_h = tf.summary.histogram(\"bias\", b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope( \"cost_func\") as scope:\n",
    "    cost= tf.reduce_sum(y*tf.log(model))\n",
    "    tf.summary.scalar(\"cost_func\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope( \"GD\") as scope:\n",
    "    GD = tf.train.GradientDescentOptimizer(0.05).minimize(cost)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "merged_summary_operator = tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'input_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-d60c20d371bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'input_data'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-154e37c7ad6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msummary_writer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mitr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist_train' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter('./logs', graph = session.graph)\n",
    "    for itr in range(1000):\n",
    "        batch_xs, batch_ys = mnist_train.next_batch(batch_size)\n",
    "        session.run(GD, feed_dict= {x: batch_xs, y:batch_ys})\n",
    "        \n",
    "        avg_cost = session.run(cost_func, feed_dict = {x:batch_xs, y:batch_ys})\n",
    "        \n",
    "        summary_str = session.run(merged_summary_operator, feed_dict={x:batch_xs, y:batch_ys})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(train)\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8\n",
      "2.44\n",
      "2.9520001\n",
      "3.3616002\n",
      "3.68928\n",
      "3.9514241\n",
      "4.1611395\n",
      "4.328912\n",
      "4.4631295\n",
      "4.5705037\n",
      "4.656403\n",
      "4.7251225\n",
      "4.780098\n",
      "4.8240786\n",
      "4.859263\n",
      "4.88741\n",
      "4.9099283\n",
      "4.9279428\n",
      "4.942354\n",
      "4.953883\n",
      "4.9631066\n",
      "4.970485\n",
      "4.976388\n",
      "4.9811106\n",
      "4.9848886\n",
      "4.9879107\n",
      "4.990329\n",
      "4.992263\n",
      "4.99381\n",
      "4.995048\n",
      "4.9960384\n",
      "4.996831\n",
      "4.9974647\n",
      "4.9979715\n",
      "4.9983773\n",
      "4.998702\n",
      "4.9989614\n",
      "4.9991693\n",
      "4.9993353\n",
      "4.9994683\n",
      "4.9995747\n",
      "4.9996595\n",
      "4.9997277\n",
      "4.999782\n",
      "4.9998255\n",
      "4.9998603\n",
      "4.9998884\n",
      "4.999911\n",
      "4.9999285\n",
      "4.999943\n",
      "4.999954\n",
      "4.9999633\n",
      "4.9999704\n",
      "4.999976\n",
      "4.999981\n",
      "4.9999847\n",
      "4.9999876\n",
      "4.99999\n",
      "4.999992\n",
      "4.9999933\n",
      "4.9999948\n",
      "4.9999957\n",
      "4.9999967\n",
      "4.999997\n",
      "4.9999976\n",
      "4.999998\n",
      "4.9999986\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n",
      "4.999999\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    session.run(train)\n",
    "    print(session.run(w))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4196352 into shape (784,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-add2d57b99dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata_dirx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/Users/rupes/OneDrive/Pictures/Screenshots/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_test_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_mnistx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dirx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mY_test_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_test_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\7th_Sem\\Machine Learning\\Assignments\\Assignment_2\\src\\data_util.py\u001b[0m in \u001b[0;36mload_mnistx\u001b[1;34m(path, nlabels)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"/*.png\"\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m                 \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 4196352 into shape (784,)"
     ]
    }
   ],
   "source": [
    "data_dirx = 'C:/Users/rupes/OneDrive/Pictures/Screenshots/'\n",
    "X_test_1, Y_test_1 = du.load_mnistx(data_dirx,1)\n",
    "Y_test_1 = Y_test_1.reshape(len(Y_test_1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BTP",
   "language": "python",
   "name": "btp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
